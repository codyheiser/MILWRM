<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>MILWRM.MxIF API documentation</title>
<meta name="description" content="Functions and classes for analyzing multiplex imaging data" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>MILWRM.MxIF</code></h1>
</header>
<section id="section-intro">
<p>Functions and classes for analyzing multiplex imaging data</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Functions and classes for analyzing multiplex imaging data
&#34;&#34;&#34;
import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns
from sklearn.utils import shuffle
from sklearn.cluster import KMeans

sns.set_style(&#34;white&#34;)
plt.rcParams[&#34;font.family&#34;] = &#34;monospace&#34;

from math import ceil
from skimage import exposure
from skimage.io import imread
from skimage.measure import block_reduce
from matplotlib.lines import Line2D
from skimage import filters
from skimage.restoration import denoise_bilateral


def checktype(obj):
    return bool(obj) and all(isinstance(elem, str) for elem in obj)


def clip_values(image, channels=None):
    &#34;&#34;&#34;
    Clip outlier values from specified channels of an image

    Parameters
    ----------
    image : np.ndarray
        The image
    channels : tuple of int or None, optional (default=`None`)
        Channels to clip on img.shape[2]. If None, clip values in all channels.

    Returns
    -------
    image_cp : np.ndarray
        Image with clipped values
    &#34;&#34;&#34;
    image_cp = image.copy()
    if channels is None or image.ndim == 2:
        vmin, vmax = np.nanpercentile(image_cp[image_cp != -99999], q=(0.5, 99.5))
        plane_clip = exposure.rescale_intensity(
            image_cp,
            in_range=(vmin, vmax),
            out_range=np.float32,
        )
        image_cp = plane_clip
    else:
        for z in channels:
            plane = image_cp[:, :, z].copy()
            vmin, vmax = np.nanpercentile(plane, q=(0.5, 99.5))
            plane_clip = exposure.rescale_intensity(
                plane,
                in_range=(vmin, vmax),
                out_range=np.float32,
            )
            image_cp[:, :, z] = plane_clip
    return image_cp


def scale_rgb(image, channels=None):
    &#34;&#34;&#34;
    Scale to [0.0, 1.0] for RGB image

    Parameters
    ----------
    image : np.ndarray
        The image
    channels : tuple of int or None, optional (default=`None`)
        Channels to scale on img.shape[2]. If None, scale values in all channels.

    Returns
    -------
    image_cp : np.ndarray
        Image with scaled values
    &#34;&#34;&#34;
    image_cp = image.copy()
    if channels is None or image.ndim == 2:
        image_cp = image_cp - image_cp.min()
        image_cp = image_cp / image_cp.max()
    else:
        for z in channels:
            plane = image_cp[:, :, z].copy()
            plane = plane - plane.min()
            image_cp[:, :, z] = plane / plane.max()
    return image_cp


def CLAHE(image, channels=None, **kwargs):
    &#34;&#34;&#34;
    Contrast Limited Adaptive Histogram Equalization (CLAHE)

    Parameters
    ----------
    image : np.ndarray
        The image
    channels : tuple of int or None, optional (default=`None`)
        Channels to adjust on image.shape[2]. If None, perform CLAHE in all channels.
    **kwargs
        Keyword arguments to pass to `skimage.exposure.equalize_adapthist`

    Returns
    -------
    image_cp : np.ndarray
        Image with exposure-adjusted values
    &#34;&#34;&#34;
    image_cp = image.copy()
    if image.ndim == 2:
        image_cp = exposure.equalize_adapthist(image_cp, **kwargs)
    elif channels is None:
        for z in range(image_cp.shape[2]):
            image_cp[:, :, z] = exposure.equalize_adapthist(image_cp[:, :, z], **kwargs)
    else:
        for z in channels:
            image_cp[:, :, z] = exposure.equalize_adapthist(image_cp[:, :, z], **kwargs)
    return image_cp


class img:
    def __init__(self, img_arr, channels=None, mask=None):
        &#34;&#34;&#34;
        Initialize img class

        Parameters
        ----------
        img_arr : np.ndarray
            The image as a numpy array
        channels : list of str or None, optional (default=`None`)
            List of channel names corresponding to img.shape[2]. i.e. `(&#34;DAPI&#34;,&#34;GFAP&#34;,
            &#34;NeuH&#34;)`. If `None`, channels are named &#34;ch_0&#34;, &#34;ch_1&#34;, etc.
        mask : np.ndarray
            Mask defining pixels containing tissue in the image

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        assert (
            img_arr.ndim &gt; 1
        ), &#34;Image does not have enough dimensions: {} given&#34;.format(img_arr.ndim)
        self.img = img_arr.astype(&#34;float64&#34;)  # save image array to .img attribute
        if img_arr.ndim &gt; 2:
            self.n_ch = img_arr.shape[2]  # save number of channels to attribute
        else:
            self.n_ch = 1
        if channels is None:
            # if channel names not specified, name them numerically
            self.ch = [&#34;ch_{}&#34;.format(x) for x in range(self.n_ch)]
        else:
            if not isinstance(channels, list):
                raise Exception(&#34;Channels must be given in a list&#34;)
            assert (
                len(channels) == self.n_ch
            ), &#34;Number of channels must match img_arr.shape[2]&#34;
            self.ch = channels
        if mask is not None:
            # validate that mask matches img_arr
            assert (
                mask.shape == img_arr.shape[:2]
            ), &#34;Shape of mask must match the first two dimensions of img_arr&#34;
        self.mask = mask  # set mask attribute, regardless of value given

    def __repr__(self) -&gt; str:
        &#34;&#34;&#34;Representation of contents of img object&#34;&#34;&#34;
        descr = &#34;img object with {} of {} and shape {}px x {}px\n&#34;.format(
            type(self.img),
            self.img.dtype,
            self.img.shape[0],
            self.img.shape[1],
        ) + &#34;{} image channels:\n\t{}&#34;.format(self.n_ch, self.ch)
        if self.mask is not None:
            descr += &#34;\n\ntissue mask {} of {} and shape {}px x {}px&#34;.format(
                type(self.mask),
                self.mask.dtype,
                self.mask.shape[0],
                self.mask.shape[1],
            )
        return descr

    def copy(self) -&gt; &#34;img&#34;:
        &#34;&#34;&#34;Full copy of img object&#34;&#34;&#34;
        new = {}
        for key in [&#34;img&#34;, &#34;ch&#34;, &#34;mask&#34;]:
            attr = self.__getattribute__(key)
            if attr is not None:
                new[key] = attr.copy()
            else:
                new[key] = None
        return img(img_arr=new[&#34;img&#34;], channels=new[&#34;ch&#34;], mask=new[&#34;mask&#34;])

    def __getitem__(self, channels):
        &#34;&#34;&#34;Slice img object with channel name(s)&#34;&#34;&#34;
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self.ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self.ch.index(x) for x in channels]

        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self.n_ch)]

        return self.img[:, :, channels]

    @classmethod
    def from_tiffs(cls, tiffdir, channels, common_strings=None, mask=None):
        &#34;&#34;&#34;
        Initialize img class from `.tif` files

        Parameters
        ----------
        tiffdir : str
            Path to directory containing `.tif` files for a multiplexed image
        channels : list of str
            List of channels present in `.tif` file names (case-sensitive)
            corresponding to img.shape[2] e.g. `(&#34;ACTG1&#34;,&#34;BCATENIN&#34;,&#34;DAPI&#34;,...)`
        common_strings : str, list of str, or `None`, optional (default=None)
            Strings to look for in all `.tif` files in `tiffdir` corresponding to
            `channels` e.g. `(&#34;WD86055_&#34;, &#34;_region_001.tif&#34;)` for files named
            &#34;WD86055_[MARKERNAME]_region_001.tif&#34;. If `None`, assume that only 1 image
            for each marker in `channels` is present in `tiffdir`.
        mask : str, optional (default=None)
            Name of mask defining pixels containing tissue in the image, present in
            `.tif` file names (case-sensitive) e.g. &#34;_01_TISSUE_MASK.tif&#34;

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        if common_strings is not None:
            # coerce single string to list
            if isinstance(common_strings, str):
                common_strings = [common_strings]
        A = []  # list for dumping numpy arrays
        for channel in channels:
            if common_strings is None:
                # find file matching all common_strings and channel name
                f = [f for f in os.listdir(tiffdir) if channel in f]
            else:
                # find file matching all common_strings and channel name
                f = [
                    f
                    for f in os.listdir(tiffdir)
                    if all(x in f for x in common_strings + [channel])
                ]
            # assertions so we only get one file per channel
            assert len(f) != 0, &#34;No file found with channel {}&#34;.format(channel)
            assert (
                len(f) == 1
            ), &#34;More than one match found for file with channel {}&#34;.format(channel)
            f = os.path.join(tiffdir, f[0])  # get full path to file for reading
            print(&#34;Reading marker {} from {}&#34;.format(channel, f))
            tmp = imread(f)  # read in .tif file
            A.append(tmp)  # append numpy array to list
        A_arr = np.dstack(
            A
        )  # stack numpy arrays in new dimension (third dim is channel)
        print(&#34;Final image array of shape: {}&#34;.format(A_arr.shape))
        # read in tissue mask if available
        if mask is not None:
            f = [f for f in os.listdir(tiffdir) if mask in f]
            # assertions so we only get one mask file
            assert len(f) != 0, &#34;No tissue mask file found&#34;
            assert len(f) == 1, &#34;More than one match found for tissue mask file&#34;
            f = os.path.join(tiffdir, f[0])  # get full path to file for reading
            print(&#34;Reading tissue mask from {}&#34;.format(f))
            A_mask = imread(f)  # read in .tif file
            assert (
                A_mask.shape == A_arr.shape[:2]
            ), &#34;Mask (shape: {}) is not the same shape as marker images (shape: {})&#34;.format(
                A_mask.shape, A_arr.shape[:2]
            )
            print(&#34;Final mask array of shape: {}&#34;.format(A_mask.shape))
        else:
            A_mask = None
        # generate img object
        return cls(img_arr=A_arr, channels=channels, mask=A_mask)

    @classmethod
    def from_npz(cls, file):
        &#34;&#34;&#34;
        Initialize img class from `.npz` file

        Parameters
        ----------
        file : str
            Path to `.npz` file containing saved img object and metadata

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        print(&#34;Loading img object from {}...&#34;.format(file))
        tmp = np.load(file)  # load from .npz compressed file
        assert (
            &#34;img&#34; in tmp.files
        ), &#34;Unexpected files in .npz: {}, expected [&#39;img&#39;,&#39;mask&#39;,&#39;ch&#39;].&#34;.format(
            tmp.files
        )
        A_mask = tmp[&#34;mask&#34;] if &#34;mask&#34; in tmp.files else None
        A_ch = list(tmp[&#34;ch&#34;]) if &#34;ch&#34; in tmp.files else None
        # generate img object
        return cls(img_arr=tmp[&#34;img&#34;], channels=A_ch, mask=A_mask)

    def to_npz(self, file):
        &#34;&#34;&#34;
        Save img object to compressed `.npz` file

        Parameters
        ----------
        file : str
            Path to `.npz` file in which to save img object and metadata

        Returns
        -------
        Writes object to `file`
        &#34;&#34;&#34;
        print(&#34;Saving img object to {}...&#34;.format(file))
        if self.mask is None:
            np.savez_compressed(file, img=self.img, ch=self.ch)
        else:
            np.savez_compressed(file, img=self.img, ch=self.ch, mask=self.mask)

    def clip(self, **kwargs):
        &#34;&#34;&#34;
        Clips outlier values and rescales intensities

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `clip_values()` function

        Returns
        -------
        Clips outlier values from `self.img`
        &#34;&#34;&#34;
        self.img = clip_values(self.img, **kwargs)

    def scale(self, **kwargs):
        &#34;&#34;&#34;
        Scales intensities to [0.0, 1.0]

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `scale_rgb()` function

        Returns
        -------
        Scales intensities of `self.img`
        &#34;&#34;&#34;
        self.img = scale_rgb(self.img, **kwargs)

    def equalize_hist(self, **kwargs):
        &#34;&#34;&#34;
        Contrast Limited Adaptive Histogram Equalization (CLAHE)

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `CLAHE()` function

        Returns
        -------
        `self.img` is updated with exposure-adjusted values
        &#34;&#34;&#34;
        self.img = CLAHE(self.img, **kwargs)

    def blurring(self, filter_name=&#34;gaussian&#34;, sigma=2, **kwargs):
        &#34;&#34;&#34;
        Aplying a filter on the images

        Parameters
        ----------
        filter : str
            str to define which type of filter to apply

        sigma : int
            parameter controlling extent of smoothening
        &#34;&#34;&#34;
        if filter_name == &#34;gaussian&#34;:
            print(&#34;Applying gaussian filter&#34;)
            self.img = filters.gaussian(
                self.img,
                sigma=sigma,
                channel_axis=2,
                **kwargs,
            )
        elif filter_name == &#34;median&#34;:
            print(&#34;Applying median filter&#34;)
            if isinstance(sigma, float):
                sigma = int(sigma)
            for i in range(self.img.shape[2]):
                image_array = self.img[:, :, i]
                image_array_blurred = filters.median(
                    image_array,
                    np.ones(sigma, sigma),
                )
                self.img[:, :, i] = image_array_blurred
        elif filter_name == &#34;bilateral&#34;:
            print(&#34;Applying biltaral filter&#34;)
            self.img = denoise_bilateral(
                self.img, sigma_spatial=sigma, channel_axis=2, **kwargs
            )
        else:
            raise Exception(
                &#34;filter name should be either gaussian, median or bilateral&#34;
            )

    def log_normalize(self, pseudoval=1, mean=None, mask=True):
        &#34;&#34;&#34;
        Log-normalizes values for each marker with `log10(arr/arr.mean() + pseudoval)`

        Parameters
        ----------
        pseudoval : float
            Value to add to image values prior to log-transforming to avoid issues
            with zeros
        mask : bool, optional (default=True)
            Use tissue mask to determine marker mean factor for normalization. Default
            `True`.

        Returns
        -------
        Log-normalizes values in each channel of `self.img`
        &#34;&#34;&#34;
        if mean is not None:
            if mask:
                assert self.mask is not None, &#34;No tissue mask available&#34;
                for i in range(self.img.shape[2]):
                    fact = mean[i]
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
            else:
                print(&#34;WARNING: Performing normalization without a tissue mask.&#34;)
                for i in range(self.img.shape[2]):
                    fact = mean[i]
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
        else:
            print(&#34;mean calculated to perform log normalization&#34;)
            if mask:
                assert self.mask is not None, &#34;No tissue mask available&#34;
                for i in range(self.img.shape[2]):
                    fact = self.img[:, :, i].mean()
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
            else:
                print(&#34;WARNING: Performing normalization without a tissue mask.&#34;)
                for i in range(self.img.shape[2]):
                    fact = self.img[:, :, i].mean()
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)

    def subsample_pixels(self, features, fract=0.2, random_state=18):
        &#34;&#34;&#34;
        Sub-samples fraction of pixels from the image randomly for each channel

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select
            for model building

        Returns
        -------
        tmp : np.array
            Clustering data from `image`

        &#34;&#34;&#34;
        if isinstance(features, int):  # force features into list if single integer
            features = [features]
        if isinstance(features, str):  # force features into int if single string
            features = [self.ch.index(features)]
        if checktype(features):  # force features into list of int if list of strings
            features = [self.ch.index(x) for x in features]
        if features is None:  # if no features are given, use all of them
            features = [x for x in range(self.n_ch)]
        # subsample data for given image
        np.random.seed(random_state)
        tmp = []
        for i in range(self.img.shape[2]):
            tmp.append(self.img[:, :, i][self.mask != 0])
        tmp = np.column_stack(tmp)
        # select cluster data
        i = np.random.choice(tmp.shape[0], int(tmp.shape[0] * fract))
        tmp = tmp[np.ix_(i, features)]
        return tmp

    def downsample(self, fact, func=np.mean):
        &#34;&#34;&#34;
        Downsamples image by applying `func` to `fact` pixels in both directions from
        each pixel

        Parameters
        ----------
        fact : int
            Number of pixels in each direction (x &amp; y) to downsample with
        func : function
            Numpy function to apply to squares of size (fact, fact, :) for downsampling
            (e.g. `np.mean`, `np.max`, `np.sum`)

        Returns
        -------
        self.img and self.mask are downsampled accordingly in place
        &#34;&#34;&#34;
        # downsample mask if mask available
        if self.mask is not None:
            self.mask = block_reduce(
                self.mask, block_size=(fact, fact), func=func, cval=0
            )
        # downsample image
        self.img = block_reduce(self.img, block_size=(fact, fact, 1), func=func, cval=0)

    def calculate_non_zero_mean(self):
        &#34;&#34;&#34;
        Calculate mean estimator for the given image array avoiding mask pixels or
        pixels with value 0

        Parameters
        ----------

        Returns
        -------
        mean_estimator : list of float
            List of mean estimator (mean*pixel) values for each channel
        pixels : int
            pixel count for the image excluding masked pixels
        &#34;&#34;&#34;
        image = self.img
        pixels = np.count_nonzero(image != 0)
        mean_estimator = []
        for i in range(image.shape[2]):
            ar = image[:, :, i]
            mean = ar[ar != 0].mean()
            mean_estimator.append(mean * pixels)
        return mean_estimator, pixels

    def create_tissue_mask(self, features=None, fract=0.2):
        &#34;&#34;&#34;
        Create tissue mask

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select
            for model building

        Returns
        -------
        a numpy array as tissue mask set to self.mask
        &#34;&#34;&#34;
        # create a copy of the image
        image_cp = self.copy()
        # create a temporary tissue mask that covers no region
        w, h, d = image_cp.img.shape
        image_cp.mask = np.ones((w, h))
        # log normalization on image
        image_cp.log_normalize()
        # apply gaussian filter
        image_cp.img = filters.gaussian(image_cp.img, sigma=2, channel_axis=2)
        # subsample data to build kmeans model
        subsampled_data = image_cp.subsample_pixels(features, fract=fract)
        cluster_data = np.row_stack(subsampled_data)
        # reshape image for prediction
        image_ar_reshape = image_cp.img.reshape((w * h, d))
        # build kmeans model with 2 clusters
        kmeans = KMeans(n_clusters=2, random_state=18).fit(cluster_data)
        labels = kmeans.predict(image_ar_reshape).astype(float)
        tID = labels.reshape((w, h))
        # check if the background is labelled as 0 or 1
        scores = kmeans.cluster_centers_
        mean = scores.mean()
        std = scores.std()
        z_scores = (scores - mean) / std
        if z_scores[0].mean() &gt; 0:
            where_0 = np.where(tID == 0.0)
            tID[where_0] = 0.5
            where_1 = np.where(tID == 1.0)
            tID[where_1] = 0.0
            where_05 = np.where(tID == 0.5)
            tID[where_05] = 1.0
        self.mask = tID

    def show(
        self,
        channels=None,
        RGB=False,
        cbar=False,
        mask_out=True,
        ncols=4,
        figsize=(7, 7),
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot image

        Parameters
        ----------
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        RGB : bool
            Treat 3- or 4-dimensional array as RGB image. If `False`, plot channels
            individually.
        cbar : bool
            Show colorbar for scale of image intensities if plotting individual
            channels.
        mask_out : bool, optional (default=`True`)
            Mask out non-tissue pixels prior to showing
        ncols : int
            Number of columns for gridspec if plotting individual channels.
        figsize : tuple of float
            Size in inches of output figure.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        # if only one feature (2D), plot it quickly
        if self.img.ndim == 2:
            fig = plt.figure(figsize=figsize)
            if self.mask is not None and mask_out:
                im_tmp = self.img.copy()  # make copy for masking
                im_tmp[:, :][self.mask == 0] = np.nan  # area outside mask to NaN
                plt.imshow(im_tmp, **kwargs)
            else:
                plt.imshow(self.img, **kwargs)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            if cbar:
                plt.colorbar(shrink=0.8)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
                )
            return fig
        # if image has multiple channels, plot them in gridspec
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self.ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self.ch.index(x) for x in channels]
        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self.n_ch)]
        assert (
            len(channels) &lt;= self.n_ch
        ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
            self.n_ch, len(channels)
        )
        if RGB:
            # if third dim has 3 or 4 features, treat as RGB and plot it quickly
            assert (self.img.ndim == 3) &amp; (
                len(channels) == 3
            ), &#34;Need 3 dimensions and 3 given channels for an RGB image; shape = {}; channels given = {}&#34;.format(
                self.img.shape, len(channels)
            )
            fig = plt.figure(figsize=figsize)
            # rearrange channels to specified order
            im_tmp = np.dstack(
                [
                    self.img[:, :, channels[0]],
                    self.img[:, :, channels[1]],
                    self.img[:, :, channels[2]],
                ]
            )
            if self.mask is not None and mask_out:
                for i in [0, 1, 2]:  # for 3-channel image
                    im_tmp[:, :, i][self.mask == 0] = np.nan  # area outside mask NaN
            plt.imshow(im_tmp, **kwargs)
            # add legend for channel IDs
            custom_lines = [
                Line2D([0], [0], color=(1, 0, 0), lw=5),
                Line2D([0], [0], color=(0, 1, 0), lw=5),
                Line2D([0], [0], color=(0, 0, 1), lw=5),
            ]
            plt.legend(custom_lines, [self.ch[x] for x in channels], fontsize=&#34;medium&#34;)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300
                )
            return fig
        # calculate gridspec dimensions
        if len(channels) &lt;= ncols:
            n_rows, n_cols = 1, len(channels)
        else:
            n_rows, n_cols = ceil(len(channels) / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        for channel in channels:
            ax = plt.subplot(gs[i])
            if self.mask is not None and mask_out:
                im_tmp = self.img[:, :, channel].copy()  # make copy for masking
                im_tmp[self.mask == 0] = np.nan  # area outside mask NaN
                im = ax.imshow(im_tmp, **kwargs)
            else:
                im = ax.imshow(self.img[:, :, channel], **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=self.ch[channel],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            if cbar:
                _ = plt.colorbar(im, shrink=0.8)
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def plot_image_histogram(self, channels=None, ncols=4, save_to=None, **kwargs):

        &#34;&#34;&#34;
        Plot image histogram

        Parameters
        ----------
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        ncols : int
            Number sof columns for gridspec if plotting individual channels.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Gridspec object (for multiple features). Saves plot to file if `save_to` is
        not `None`.
        &#34;&#34;&#34;
        # calculate gridspec dimensions
        if len(channels) &lt;= ncols:
            n_rows, n_cols = 1, len(channels)
        else:
            n_rows, n_cols = ceil(len(channels) / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        for channel in channels:
            ax = plt.subplot(gs[i])
            data = self[channel].copy()
            ax.hist(data.ravel(), bins=100, **kwargs)
            ax.set_title(channel, fontweight=&#34;bold&#34;, fontsize=16)
            i = i + 1
        fig.tight_layout()
        plt.show()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return gs</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="MILWRM.MxIF.CLAHE"><code class="name flex">
<span>def <span class="ident">CLAHE</span></span>(<span>image, channels=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Contrast Limited Adaptive Histogram Equalization (CLAHE)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Channels to adjust on image.shape[2]. If None, perform CLAHE in all channels.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments to pass to <code>skimage.exposure.equalize_adapthist</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>image_cp</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image with exposure-adjusted values</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CLAHE(image, channels=None, **kwargs):
    &#34;&#34;&#34;
    Contrast Limited Adaptive Histogram Equalization (CLAHE)

    Parameters
    ----------
    image : np.ndarray
        The image
    channels : tuple of int or None, optional (default=`None`)
        Channels to adjust on image.shape[2]. If None, perform CLAHE in all channels.
    **kwargs
        Keyword arguments to pass to `skimage.exposure.equalize_adapthist`

    Returns
    -------
    image_cp : np.ndarray
        Image with exposure-adjusted values
    &#34;&#34;&#34;
    image_cp = image.copy()
    if image.ndim == 2:
        image_cp = exposure.equalize_adapthist(image_cp, **kwargs)
    elif channels is None:
        for z in range(image_cp.shape[2]):
            image_cp[:, :, z] = exposure.equalize_adapthist(image_cp[:, :, z], **kwargs)
    else:
        for z in channels:
            image_cp[:, :, z] = exposure.equalize_adapthist(image_cp[:, :, z], **kwargs)
    return image_cp</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.checktype"><code class="name flex">
<span>def <span class="ident">checktype</span></span>(<span>obj)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def checktype(obj):
    return bool(obj) and all(isinstance(elem, str) for elem in obj)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.clip_values"><code class="name flex">
<span>def <span class="ident">clip_values</span></span>(<span>image, channels=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clip outlier values from specified channels of an image</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Channels to clip on img.shape[2]. If None, clip values in all channels.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>image_cp</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image with clipped values</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clip_values(image, channels=None):
    &#34;&#34;&#34;
    Clip outlier values from specified channels of an image

    Parameters
    ----------
    image : np.ndarray
        The image
    channels : tuple of int or None, optional (default=`None`)
        Channels to clip on img.shape[2]. If None, clip values in all channels.

    Returns
    -------
    image_cp : np.ndarray
        Image with clipped values
    &#34;&#34;&#34;
    image_cp = image.copy()
    if channels is None or image.ndim == 2:
        vmin, vmax = np.nanpercentile(image_cp[image_cp != -99999], q=(0.5, 99.5))
        plane_clip = exposure.rescale_intensity(
            image_cp,
            in_range=(vmin, vmax),
            out_range=np.float32,
        )
        image_cp = plane_clip
    else:
        for z in channels:
            plane = image_cp[:, :, z].copy()
            vmin, vmax = np.nanpercentile(plane, q=(0.5, 99.5))
            plane_clip = exposure.rescale_intensity(
                plane,
                in_range=(vmin, vmax),
                out_range=np.float32,
            )
            image_cp[:, :, z] = plane_clip
    return image_cp</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.scale_rgb"><code class="name flex">
<span>def <span class="ident">scale_rgb</span></span>(<span>image, channels=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Scale to [0.0, 1.0] for RGB image</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Channels to scale on img.shape[2]. If None, scale values in all channels.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>image_cp</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image with scaled values</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale_rgb(image, channels=None):
    &#34;&#34;&#34;
    Scale to [0.0, 1.0] for RGB image

    Parameters
    ----------
    image : np.ndarray
        The image
    channels : tuple of int or None, optional (default=`None`)
        Channels to scale on img.shape[2]. If None, scale values in all channels.

    Returns
    -------
    image_cp : np.ndarray
        Image with scaled values
    &#34;&#34;&#34;
    image_cp = image.copy()
    if channels is None or image.ndim == 2:
        image_cp = image_cp - image_cp.min()
        image_cp = image_cp / image_cp.max()
    else:
        for z in channels:
            plane = image_cp[:, :, z].copy()
            plane = plane - plane.min()
            image_cp[:, :, z] = plane / plane.max()
    return image_cp</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="MILWRM.MxIF.img"><code class="flex name class">
<span>class <span class="ident">img</span></span>
<span>(</span><span>img_arr, channels=None, mask=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize img class</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>img_arr</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image as a numpy array</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of channel names corresponding to img.shape[2]. i.e. <code>("DAPI","GFAP",
"NeuH")&lt;code&gt;. If &lt;/code&gt;None</code>, channels are named "ch_0", "ch_1", etc.</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Mask defining pixels containing tissue in the image</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="MILWRM.MxIF.img" href="#MILWRM.MxIF.img">img</a></code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class img:
    def __init__(self, img_arr, channels=None, mask=None):
        &#34;&#34;&#34;
        Initialize img class

        Parameters
        ----------
        img_arr : np.ndarray
            The image as a numpy array
        channels : list of str or None, optional (default=`None`)
            List of channel names corresponding to img.shape[2]. i.e. `(&#34;DAPI&#34;,&#34;GFAP&#34;,
            &#34;NeuH&#34;)`. If `None`, channels are named &#34;ch_0&#34;, &#34;ch_1&#34;, etc.
        mask : np.ndarray
            Mask defining pixels containing tissue in the image

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        assert (
            img_arr.ndim &gt; 1
        ), &#34;Image does not have enough dimensions: {} given&#34;.format(img_arr.ndim)
        self.img = img_arr.astype(&#34;float64&#34;)  # save image array to .img attribute
        if img_arr.ndim &gt; 2:
            self.n_ch = img_arr.shape[2]  # save number of channels to attribute
        else:
            self.n_ch = 1
        if channels is None:
            # if channel names not specified, name them numerically
            self.ch = [&#34;ch_{}&#34;.format(x) for x in range(self.n_ch)]
        else:
            if not isinstance(channels, list):
                raise Exception(&#34;Channels must be given in a list&#34;)
            assert (
                len(channels) == self.n_ch
            ), &#34;Number of channels must match img_arr.shape[2]&#34;
            self.ch = channels
        if mask is not None:
            # validate that mask matches img_arr
            assert (
                mask.shape == img_arr.shape[:2]
            ), &#34;Shape of mask must match the first two dimensions of img_arr&#34;
        self.mask = mask  # set mask attribute, regardless of value given

    def __repr__(self) -&gt; str:
        &#34;&#34;&#34;Representation of contents of img object&#34;&#34;&#34;
        descr = &#34;img object with {} of {} and shape {}px x {}px\n&#34;.format(
            type(self.img),
            self.img.dtype,
            self.img.shape[0],
            self.img.shape[1],
        ) + &#34;{} image channels:\n\t{}&#34;.format(self.n_ch, self.ch)
        if self.mask is not None:
            descr += &#34;\n\ntissue mask {} of {} and shape {}px x {}px&#34;.format(
                type(self.mask),
                self.mask.dtype,
                self.mask.shape[0],
                self.mask.shape[1],
            )
        return descr

    def copy(self) -&gt; &#34;img&#34;:
        &#34;&#34;&#34;Full copy of img object&#34;&#34;&#34;
        new = {}
        for key in [&#34;img&#34;, &#34;ch&#34;, &#34;mask&#34;]:
            attr = self.__getattribute__(key)
            if attr is not None:
                new[key] = attr.copy()
            else:
                new[key] = None
        return img(img_arr=new[&#34;img&#34;], channels=new[&#34;ch&#34;], mask=new[&#34;mask&#34;])

    def __getitem__(self, channels):
        &#34;&#34;&#34;Slice img object with channel name(s)&#34;&#34;&#34;
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self.ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self.ch.index(x) for x in channels]

        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self.n_ch)]

        return self.img[:, :, channels]

    @classmethod
    def from_tiffs(cls, tiffdir, channels, common_strings=None, mask=None):
        &#34;&#34;&#34;
        Initialize img class from `.tif` files

        Parameters
        ----------
        tiffdir : str
            Path to directory containing `.tif` files for a multiplexed image
        channels : list of str
            List of channels present in `.tif` file names (case-sensitive)
            corresponding to img.shape[2] e.g. `(&#34;ACTG1&#34;,&#34;BCATENIN&#34;,&#34;DAPI&#34;,...)`
        common_strings : str, list of str, or `None`, optional (default=None)
            Strings to look for in all `.tif` files in `tiffdir` corresponding to
            `channels` e.g. `(&#34;WD86055_&#34;, &#34;_region_001.tif&#34;)` for files named
            &#34;WD86055_[MARKERNAME]_region_001.tif&#34;. If `None`, assume that only 1 image
            for each marker in `channels` is present in `tiffdir`.
        mask : str, optional (default=None)
            Name of mask defining pixels containing tissue in the image, present in
            `.tif` file names (case-sensitive) e.g. &#34;_01_TISSUE_MASK.tif&#34;

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        if common_strings is not None:
            # coerce single string to list
            if isinstance(common_strings, str):
                common_strings = [common_strings]
        A = []  # list for dumping numpy arrays
        for channel in channels:
            if common_strings is None:
                # find file matching all common_strings and channel name
                f = [f for f in os.listdir(tiffdir) if channel in f]
            else:
                # find file matching all common_strings and channel name
                f = [
                    f
                    for f in os.listdir(tiffdir)
                    if all(x in f for x in common_strings + [channel])
                ]
            # assertions so we only get one file per channel
            assert len(f) != 0, &#34;No file found with channel {}&#34;.format(channel)
            assert (
                len(f) == 1
            ), &#34;More than one match found for file with channel {}&#34;.format(channel)
            f = os.path.join(tiffdir, f[0])  # get full path to file for reading
            print(&#34;Reading marker {} from {}&#34;.format(channel, f))
            tmp = imread(f)  # read in .tif file
            A.append(tmp)  # append numpy array to list
        A_arr = np.dstack(
            A
        )  # stack numpy arrays in new dimension (third dim is channel)
        print(&#34;Final image array of shape: {}&#34;.format(A_arr.shape))
        # read in tissue mask if available
        if mask is not None:
            f = [f for f in os.listdir(tiffdir) if mask in f]
            # assertions so we only get one mask file
            assert len(f) != 0, &#34;No tissue mask file found&#34;
            assert len(f) == 1, &#34;More than one match found for tissue mask file&#34;
            f = os.path.join(tiffdir, f[0])  # get full path to file for reading
            print(&#34;Reading tissue mask from {}&#34;.format(f))
            A_mask = imread(f)  # read in .tif file
            assert (
                A_mask.shape == A_arr.shape[:2]
            ), &#34;Mask (shape: {}) is not the same shape as marker images (shape: {})&#34;.format(
                A_mask.shape, A_arr.shape[:2]
            )
            print(&#34;Final mask array of shape: {}&#34;.format(A_mask.shape))
        else:
            A_mask = None
        # generate img object
        return cls(img_arr=A_arr, channels=channels, mask=A_mask)

    @classmethod
    def from_npz(cls, file):
        &#34;&#34;&#34;
        Initialize img class from `.npz` file

        Parameters
        ----------
        file : str
            Path to `.npz` file containing saved img object and metadata

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        print(&#34;Loading img object from {}...&#34;.format(file))
        tmp = np.load(file)  # load from .npz compressed file
        assert (
            &#34;img&#34; in tmp.files
        ), &#34;Unexpected files in .npz: {}, expected [&#39;img&#39;,&#39;mask&#39;,&#39;ch&#39;].&#34;.format(
            tmp.files
        )
        A_mask = tmp[&#34;mask&#34;] if &#34;mask&#34; in tmp.files else None
        A_ch = list(tmp[&#34;ch&#34;]) if &#34;ch&#34; in tmp.files else None
        # generate img object
        return cls(img_arr=tmp[&#34;img&#34;], channels=A_ch, mask=A_mask)

    def to_npz(self, file):
        &#34;&#34;&#34;
        Save img object to compressed `.npz` file

        Parameters
        ----------
        file : str
            Path to `.npz` file in which to save img object and metadata

        Returns
        -------
        Writes object to `file`
        &#34;&#34;&#34;
        print(&#34;Saving img object to {}...&#34;.format(file))
        if self.mask is None:
            np.savez_compressed(file, img=self.img, ch=self.ch)
        else:
            np.savez_compressed(file, img=self.img, ch=self.ch, mask=self.mask)

    def clip(self, **kwargs):
        &#34;&#34;&#34;
        Clips outlier values and rescales intensities

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `clip_values()` function

        Returns
        -------
        Clips outlier values from `self.img`
        &#34;&#34;&#34;
        self.img = clip_values(self.img, **kwargs)

    def scale(self, **kwargs):
        &#34;&#34;&#34;
        Scales intensities to [0.0, 1.0]

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `scale_rgb()` function

        Returns
        -------
        Scales intensities of `self.img`
        &#34;&#34;&#34;
        self.img = scale_rgb(self.img, **kwargs)

    def equalize_hist(self, **kwargs):
        &#34;&#34;&#34;
        Contrast Limited Adaptive Histogram Equalization (CLAHE)

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `CLAHE()` function

        Returns
        -------
        `self.img` is updated with exposure-adjusted values
        &#34;&#34;&#34;
        self.img = CLAHE(self.img, **kwargs)

    def blurring(self, filter_name=&#34;gaussian&#34;, sigma=2, **kwargs):
        &#34;&#34;&#34;
        Aplying a filter on the images

        Parameters
        ----------
        filter : str
            str to define which type of filter to apply

        sigma : int
            parameter controlling extent of smoothening
        &#34;&#34;&#34;
        if filter_name == &#34;gaussian&#34;:
            print(&#34;Applying gaussian filter&#34;)
            self.img = filters.gaussian(
                self.img,
                sigma=sigma,
                channel_axis=2,
                **kwargs,
            )
        elif filter_name == &#34;median&#34;:
            print(&#34;Applying median filter&#34;)
            if isinstance(sigma, float):
                sigma = int(sigma)
            for i in range(self.img.shape[2]):
                image_array = self.img[:, :, i]
                image_array_blurred = filters.median(
                    image_array,
                    np.ones(sigma, sigma),
                )
                self.img[:, :, i] = image_array_blurred
        elif filter_name == &#34;bilateral&#34;:
            print(&#34;Applying biltaral filter&#34;)
            self.img = denoise_bilateral(
                self.img, sigma_spatial=sigma, channel_axis=2, **kwargs
            )
        else:
            raise Exception(
                &#34;filter name should be either gaussian, median or bilateral&#34;
            )

    def log_normalize(self, pseudoval=1, mean=None, mask=True):
        &#34;&#34;&#34;
        Log-normalizes values for each marker with `log10(arr/arr.mean() + pseudoval)`

        Parameters
        ----------
        pseudoval : float
            Value to add to image values prior to log-transforming to avoid issues
            with zeros
        mask : bool, optional (default=True)
            Use tissue mask to determine marker mean factor for normalization. Default
            `True`.

        Returns
        -------
        Log-normalizes values in each channel of `self.img`
        &#34;&#34;&#34;
        if mean is not None:
            if mask:
                assert self.mask is not None, &#34;No tissue mask available&#34;
                for i in range(self.img.shape[2]):
                    fact = mean[i]
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
            else:
                print(&#34;WARNING: Performing normalization without a tissue mask.&#34;)
                for i in range(self.img.shape[2]):
                    fact = mean[i]
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
        else:
            print(&#34;mean calculated to perform log normalization&#34;)
            if mask:
                assert self.mask is not None, &#34;No tissue mask available&#34;
                for i in range(self.img.shape[2]):
                    fact = self.img[:, :, i].mean()
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
            else:
                print(&#34;WARNING: Performing normalization without a tissue mask.&#34;)
                for i in range(self.img.shape[2]):
                    fact = self.img[:, :, i].mean()
                    self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)

    def subsample_pixels(self, features, fract=0.2, random_state=18):
        &#34;&#34;&#34;
        Sub-samples fraction of pixels from the image randomly for each channel

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select
            for model building

        Returns
        -------
        tmp : np.array
            Clustering data from `image`

        &#34;&#34;&#34;
        if isinstance(features, int):  # force features into list if single integer
            features = [features]
        if isinstance(features, str):  # force features into int if single string
            features = [self.ch.index(features)]
        if checktype(features):  # force features into list of int if list of strings
            features = [self.ch.index(x) for x in features]
        if features is None:  # if no features are given, use all of them
            features = [x for x in range(self.n_ch)]
        # subsample data for given image
        np.random.seed(random_state)
        tmp = []
        for i in range(self.img.shape[2]):
            tmp.append(self.img[:, :, i][self.mask != 0])
        tmp = np.column_stack(tmp)
        # select cluster data
        i = np.random.choice(tmp.shape[0], int(tmp.shape[0] * fract))
        tmp = tmp[np.ix_(i, features)]
        return tmp

    def downsample(self, fact, func=np.mean):
        &#34;&#34;&#34;
        Downsamples image by applying `func` to `fact` pixels in both directions from
        each pixel

        Parameters
        ----------
        fact : int
            Number of pixels in each direction (x &amp; y) to downsample with
        func : function
            Numpy function to apply to squares of size (fact, fact, :) for downsampling
            (e.g. `np.mean`, `np.max`, `np.sum`)

        Returns
        -------
        self.img and self.mask are downsampled accordingly in place
        &#34;&#34;&#34;
        # downsample mask if mask available
        if self.mask is not None:
            self.mask = block_reduce(
                self.mask, block_size=(fact, fact), func=func, cval=0
            )
        # downsample image
        self.img = block_reduce(self.img, block_size=(fact, fact, 1), func=func, cval=0)

    def calculate_non_zero_mean(self):
        &#34;&#34;&#34;
        Calculate mean estimator for the given image array avoiding mask pixels or
        pixels with value 0

        Parameters
        ----------

        Returns
        -------
        mean_estimator : list of float
            List of mean estimator (mean*pixel) values for each channel
        pixels : int
            pixel count for the image excluding masked pixels
        &#34;&#34;&#34;
        image = self.img
        pixels = np.count_nonzero(image != 0)
        mean_estimator = []
        for i in range(image.shape[2]):
            ar = image[:, :, i]
            mean = ar[ar != 0].mean()
            mean_estimator.append(mean * pixels)
        return mean_estimator, pixels

    def create_tissue_mask(self, features=None, fract=0.2):
        &#34;&#34;&#34;
        Create tissue mask

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select
            for model building

        Returns
        -------
        a numpy array as tissue mask set to self.mask
        &#34;&#34;&#34;
        # create a copy of the image
        image_cp = self.copy()
        # create a temporary tissue mask that covers no region
        w, h, d = image_cp.img.shape
        image_cp.mask = np.ones((w, h))
        # log normalization on image
        image_cp.log_normalize()
        # apply gaussian filter
        image_cp.img = filters.gaussian(image_cp.img, sigma=2, channel_axis=2)
        # subsample data to build kmeans model
        subsampled_data = image_cp.subsample_pixels(features, fract=fract)
        cluster_data = np.row_stack(subsampled_data)
        # reshape image for prediction
        image_ar_reshape = image_cp.img.reshape((w * h, d))
        # build kmeans model with 2 clusters
        kmeans = KMeans(n_clusters=2, random_state=18).fit(cluster_data)
        labels = kmeans.predict(image_ar_reshape).astype(float)
        tID = labels.reshape((w, h))
        # check if the background is labelled as 0 or 1
        scores = kmeans.cluster_centers_
        mean = scores.mean()
        std = scores.std()
        z_scores = (scores - mean) / std
        if z_scores[0].mean() &gt; 0:
            where_0 = np.where(tID == 0.0)
            tID[where_0] = 0.5
            where_1 = np.where(tID == 1.0)
            tID[where_1] = 0.0
            where_05 = np.where(tID == 0.5)
            tID[where_05] = 1.0
        self.mask = tID

    def show(
        self,
        channels=None,
        RGB=False,
        cbar=False,
        mask_out=True,
        ncols=4,
        figsize=(7, 7),
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot image

        Parameters
        ----------
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        RGB : bool
            Treat 3- or 4-dimensional array as RGB image. If `False`, plot channels
            individually.
        cbar : bool
            Show colorbar for scale of image intensities if plotting individual
            channels.
        mask_out : bool, optional (default=`True`)
            Mask out non-tissue pixels prior to showing
        ncols : int
            Number of columns for gridspec if plotting individual channels.
        figsize : tuple of float
            Size in inches of output figure.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        # if only one feature (2D), plot it quickly
        if self.img.ndim == 2:
            fig = plt.figure(figsize=figsize)
            if self.mask is not None and mask_out:
                im_tmp = self.img.copy()  # make copy for masking
                im_tmp[:, :][self.mask == 0] = np.nan  # area outside mask to NaN
                plt.imshow(im_tmp, **kwargs)
            else:
                plt.imshow(self.img, **kwargs)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            if cbar:
                plt.colorbar(shrink=0.8)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
                )
            return fig
        # if image has multiple channels, plot them in gridspec
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self.ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self.ch.index(x) for x in channels]
        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self.n_ch)]
        assert (
            len(channels) &lt;= self.n_ch
        ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
            self.n_ch, len(channels)
        )
        if RGB:
            # if third dim has 3 or 4 features, treat as RGB and plot it quickly
            assert (self.img.ndim == 3) &amp; (
                len(channels) == 3
            ), &#34;Need 3 dimensions and 3 given channels for an RGB image; shape = {}; channels given = {}&#34;.format(
                self.img.shape, len(channels)
            )
            fig = plt.figure(figsize=figsize)
            # rearrange channels to specified order
            im_tmp = np.dstack(
                [
                    self.img[:, :, channels[0]],
                    self.img[:, :, channels[1]],
                    self.img[:, :, channels[2]],
                ]
            )
            if self.mask is not None and mask_out:
                for i in [0, 1, 2]:  # for 3-channel image
                    im_tmp[:, :, i][self.mask == 0] = np.nan  # area outside mask NaN
            plt.imshow(im_tmp, **kwargs)
            # add legend for channel IDs
            custom_lines = [
                Line2D([0], [0], color=(1, 0, 0), lw=5),
                Line2D([0], [0], color=(0, 1, 0), lw=5),
                Line2D([0], [0], color=(0, 0, 1), lw=5),
            ]
            plt.legend(custom_lines, [self.ch[x] for x in channels], fontsize=&#34;medium&#34;)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300
                )
            return fig
        # calculate gridspec dimensions
        if len(channels) &lt;= ncols:
            n_rows, n_cols = 1, len(channels)
        else:
            n_rows, n_cols = ceil(len(channels) / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        for channel in channels:
            ax = plt.subplot(gs[i])
            if self.mask is not None and mask_out:
                im_tmp = self.img[:, :, channel].copy()  # make copy for masking
                im_tmp[self.mask == 0] = np.nan  # area outside mask NaN
                im = ax.imshow(im_tmp, **kwargs)
            else:
                im = ax.imshow(self.img[:, :, channel], **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=self.ch[channel],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            if cbar:
                _ = plt.colorbar(im, shrink=0.8)
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def plot_image_histogram(self, channels=None, ncols=4, save_to=None, **kwargs):

        &#34;&#34;&#34;
        Plot image histogram

        Parameters
        ----------
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        ncols : int
            Number sof columns for gridspec if plotting individual channels.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Gridspec object (for multiple features). Saves plot to file if `save_to` is
        not `None`.
        &#34;&#34;&#34;
        # calculate gridspec dimensions
        if len(channels) &lt;= ncols:
            n_rows, n_cols = 1, len(channels)
        else:
            n_rows, n_cols = ceil(len(channels) / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        for channel in channels:
            ax = plt.subplot(gs[i])
            data = self[channel].copy()
            ax.hist(data.ravel(), bins=100, **kwargs)
            ax.set_title(channel, fontweight=&#34;bold&#34;, fontsize=16)
            i = i + 1
        fig.tight_layout()
        plt.show()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return gs</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="MILWRM.MxIF.img.from_npz"><code class="name flex">
<span>def <span class="ident">from_npz</span></span>(<span>file)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize img class from <code>.npz</code> file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to <code>.npz</code> file containing saved img object and metadata</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="MILWRM.MxIF.img" href="#MILWRM.MxIF.img">img</a></code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_npz(cls, file):
    &#34;&#34;&#34;
    Initialize img class from `.npz` file

    Parameters
    ----------
    file : str
        Path to `.npz` file containing saved img object and metadata

    Returns
    -------
    `img` object
    &#34;&#34;&#34;
    print(&#34;Loading img object from {}...&#34;.format(file))
    tmp = np.load(file)  # load from .npz compressed file
    assert (
        &#34;img&#34; in tmp.files
    ), &#34;Unexpected files in .npz: {}, expected [&#39;img&#39;,&#39;mask&#39;,&#39;ch&#39;].&#34;.format(
        tmp.files
    )
    A_mask = tmp[&#34;mask&#34;] if &#34;mask&#34; in tmp.files else None
    A_ch = list(tmp[&#34;ch&#34;]) if &#34;ch&#34; in tmp.files else None
    # generate img object
    return cls(img_arr=tmp[&#34;img&#34;], channels=A_ch, mask=A_mask)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.from_tiffs"><code class="name flex">
<span>def <span class="ident">from_tiffs</span></span>(<span>tiffdir, channels, common_strings=None, mask=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize img class from <code>.tif</code> files</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tiffdir</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to directory containing <code>.tif</code> files for a multiplexed image</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>List of channels present in <code>.tif</code> file names (case-sensitive)
corresponding to img.shape[2] e.g. <code>("ACTG1","BCATENIN","DAPI",...)</code></dd>
<dt><strong><code>common_strings</code></strong> :&ensp;<code>str, list</code> of <code>str,</code> or <code>None</code>, optional <code>(default=None)</code></dt>
<dd>Strings to look for in all <code>.tif</code> files in <code>tiffdir</code> corresponding to
<code>channels</code> e.g. <code>("WD86055_", "_region_001.tif")</code> for files named
"WD86055_[MARKERNAME]_region_001.tif". If <code>None</code>, assume that only 1 image
for each marker in <code>channels</code> is present in <code>tiffdir</code>.</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>str</code>, optional <code>(default=None)</code></dt>
<dd>Name of mask defining pixels containing tissue in the image, present in
<code>.tif</code> file names (case-sensitive) e.g. "_01_TISSUE_MASK.tif"</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="MILWRM.MxIF.img" href="#MILWRM.MxIF.img">img</a></code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_tiffs(cls, tiffdir, channels, common_strings=None, mask=None):
    &#34;&#34;&#34;
    Initialize img class from `.tif` files

    Parameters
    ----------
    tiffdir : str
        Path to directory containing `.tif` files for a multiplexed image
    channels : list of str
        List of channels present in `.tif` file names (case-sensitive)
        corresponding to img.shape[2] e.g. `(&#34;ACTG1&#34;,&#34;BCATENIN&#34;,&#34;DAPI&#34;,...)`
    common_strings : str, list of str, or `None`, optional (default=None)
        Strings to look for in all `.tif` files in `tiffdir` corresponding to
        `channels` e.g. `(&#34;WD86055_&#34;, &#34;_region_001.tif&#34;)` for files named
        &#34;WD86055_[MARKERNAME]_region_001.tif&#34;. If `None`, assume that only 1 image
        for each marker in `channels` is present in `tiffdir`.
    mask : str, optional (default=None)
        Name of mask defining pixels containing tissue in the image, present in
        `.tif` file names (case-sensitive) e.g. &#34;_01_TISSUE_MASK.tif&#34;

    Returns
    -------
    `img` object
    &#34;&#34;&#34;
    if common_strings is not None:
        # coerce single string to list
        if isinstance(common_strings, str):
            common_strings = [common_strings]
    A = []  # list for dumping numpy arrays
    for channel in channels:
        if common_strings is None:
            # find file matching all common_strings and channel name
            f = [f for f in os.listdir(tiffdir) if channel in f]
        else:
            # find file matching all common_strings and channel name
            f = [
                f
                for f in os.listdir(tiffdir)
                if all(x in f for x in common_strings + [channel])
            ]
        # assertions so we only get one file per channel
        assert len(f) != 0, &#34;No file found with channel {}&#34;.format(channel)
        assert (
            len(f) == 1
        ), &#34;More than one match found for file with channel {}&#34;.format(channel)
        f = os.path.join(tiffdir, f[0])  # get full path to file for reading
        print(&#34;Reading marker {} from {}&#34;.format(channel, f))
        tmp = imread(f)  # read in .tif file
        A.append(tmp)  # append numpy array to list
    A_arr = np.dstack(
        A
    )  # stack numpy arrays in new dimension (third dim is channel)
    print(&#34;Final image array of shape: {}&#34;.format(A_arr.shape))
    # read in tissue mask if available
    if mask is not None:
        f = [f for f in os.listdir(tiffdir) if mask in f]
        # assertions so we only get one mask file
        assert len(f) != 0, &#34;No tissue mask file found&#34;
        assert len(f) == 1, &#34;More than one match found for tissue mask file&#34;
        f = os.path.join(tiffdir, f[0])  # get full path to file for reading
        print(&#34;Reading tissue mask from {}&#34;.format(f))
        A_mask = imread(f)  # read in .tif file
        assert (
            A_mask.shape == A_arr.shape[:2]
        ), &#34;Mask (shape: {}) is not the same shape as marker images (shape: {})&#34;.format(
            A_mask.shape, A_arr.shape[:2]
        )
        print(&#34;Final mask array of shape: {}&#34;.format(A_mask.shape))
    else:
        A_mask = None
    # generate img object
    return cls(img_arr=A_arr, channels=channels, mask=A_mask)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.MxIF.img.blurring"><code class="name flex">
<span>def <span class="ident">blurring</span></span>(<span>self, filter_name='gaussian', sigma=2, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Aplying a filter on the images</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filter</code></strong> :&ensp;<code>str</code></dt>
<dd>str to define which type of filter to apply</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>int</code></dt>
<dd>parameter controlling extent of smoothening</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def blurring(self, filter_name=&#34;gaussian&#34;, sigma=2, **kwargs):
    &#34;&#34;&#34;
    Aplying a filter on the images

    Parameters
    ----------
    filter : str
        str to define which type of filter to apply

    sigma : int
        parameter controlling extent of smoothening
    &#34;&#34;&#34;
    if filter_name == &#34;gaussian&#34;:
        print(&#34;Applying gaussian filter&#34;)
        self.img = filters.gaussian(
            self.img,
            sigma=sigma,
            channel_axis=2,
            **kwargs,
        )
    elif filter_name == &#34;median&#34;:
        print(&#34;Applying median filter&#34;)
        if isinstance(sigma, float):
            sigma = int(sigma)
        for i in range(self.img.shape[2]):
            image_array = self.img[:, :, i]
            image_array_blurred = filters.median(
                image_array,
                np.ones(sigma, sigma),
            )
            self.img[:, :, i] = image_array_blurred
    elif filter_name == &#34;bilateral&#34;:
        print(&#34;Applying biltaral filter&#34;)
        self.img = denoise_bilateral(
            self.img, sigma_spatial=sigma, channel_axis=2, **kwargs
        )
    else:
        raise Exception(
            &#34;filter name should be either gaussian, median or bilateral&#34;
        )</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.calculate_non_zero_mean"><code class="name flex">
<span>def <span class="ident">calculate_non_zero_mean</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate mean estimator for the given image array avoiding mask pixels or
pixels with value 0</p>
<h2 id="parameters">Parameters</h2>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mean_estimator</code></strong> :&ensp;<code>list</code> of <code>float</code></dt>
<dd>List of mean estimator (mean*pixel) values for each channel</dd>
<dt><strong><code>pixels</code></strong> :&ensp;<code>int</code></dt>
<dd>pixel count for the image excluding masked pixels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_non_zero_mean(self):
    &#34;&#34;&#34;
    Calculate mean estimator for the given image array avoiding mask pixels or
    pixels with value 0

    Parameters
    ----------

    Returns
    -------
    mean_estimator : list of float
        List of mean estimator (mean*pixel) values for each channel
    pixels : int
        pixel count for the image excluding masked pixels
    &#34;&#34;&#34;
    image = self.img
    pixels = np.count_nonzero(image != 0)
    mean_estimator = []
    for i in range(image.shape[2]):
        ar = image[:, :, i]
        mean = ar[ar != 0].mean()
        mean_estimator.append(mean * pixels)
    return mean_estimator, pixels</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.clip"><code class="name flex">
<span>def <span class="ident">clip</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Clips outlier values and rescales intensities</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword args to pass to <code><a title="MILWRM.MxIF.clip_values" href="#MILWRM.MxIF.clip_values">clip_values()</a></code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Clips outlier values from <code>self.img</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clip(self, **kwargs):
    &#34;&#34;&#34;
    Clips outlier values and rescales intensities

    Parameters
    ----------
    **kwargs
        Keyword args to pass to `clip_values()` function

    Returns
    -------
    Clips outlier values from `self.img`
    &#34;&#34;&#34;
    self.img = clip_values(self.img, **kwargs)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self) ><a title="MILWRM.MxIF.img" href="#MILWRM.MxIF.img">img</a></span>
</code></dt>
<dd>
<div class="desc"><p>Full copy of img object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self) -&gt; &#34;img&#34;:
    &#34;&#34;&#34;Full copy of img object&#34;&#34;&#34;
    new = {}
    for key in [&#34;img&#34;, &#34;ch&#34;, &#34;mask&#34;]:
        attr = self.__getattribute__(key)
        if attr is not None:
            new[key] = attr.copy()
        else:
            new[key] = None
    return img(img_arr=new[&#34;img&#34;], channels=new[&#34;ch&#34;], mask=new[&#34;mask&#34;])</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.create_tissue_mask"><code class="name flex">
<span>def <span class="ident">create_tissue_mask</span></span>(<span>self, features=None, fract=0.2)</span>
</code></dt>
<dd>
<div class="desc"><p>Create tissue mask</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>fract</code></strong> :&ensp;<code>float</code>, optional <code>(default=0.2)</code></dt>
<dd>Fraction of cluster data from each image to randomly select
for model building</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a numpy array as tissue mask set to self.mask</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_tissue_mask(self, features=None, fract=0.2):
    &#34;&#34;&#34;
    Create tissue mask

    Parameters
    ----------
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    fract : float, optional (default=0.2)
        Fraction of cluster data from each image to randomly select
        for model building

    Returns
    -------
    a numpy array as tissue mask set to self.mask
    &#34;&#34;&#34;
    # create a copy of the image
    image_cp = self.copy()
    # create a temporary tissue mask that covers no region
    w, h, d = image_cp.img.shape
    image_cp.mask = np.ones((w, h))
    # log normalization on image
    image_cp.log_normalize()
    # apply gaussian filter
    image_cp.img = filters.gaussian(image_cp.img, sigma=2, channel_axis=2)
    # subsample data to build kmeans model
    subsampled_data = image_cp.subsample_pixels(features, fract=fract)
    cluster_data = np.row_stack(subsampled_data)
    # reshape image for prediction
    image_ar_reshape = image_cp.img.reshape((w * h, d))
    # build kmeans model with 2 clusters
    kmeans = KMeans(n_clusters=2, random_state=18).fit(cluster_data)
    labels = kmeans.predict(image_ar_reshape).astype(float)
    tID = labels.reshape((w, h))
    # check if the background is labelled as 0 or 1
    scores = kmeans.cluster_centers_
    mean = scores.mean()
    std = scores.std()
    z_scores = (scores - mean) / std
    if z_scores[0].mean() &gt; 0:
        where_0 = np.where(tID == 0.0)
        tID[where_0] = 0.5
        where_1 = np.where(tID == 1.0)
        tID[where_1] = 0.0
        where_05 = np.where(tID == 0.5)
        tID[where_05] = 1.0
    self.mask = tID</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.downsample"><code class="name flex">
<span>def <span class="ident">downsample</span></span>(<span>self, fact, func=&lt;function mean&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Downsamples image by applying <code>func</code> to <code>fact</code> pixels in both directions from
each pixel</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fact</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of pixels in each direction (x &amp; y) to downsample with</dd>
<dt><strong><code>func</code></strong> :&ensp;<code>function</code></dt>
<dd>Numpy function to apply to squares of size (fact, fact, :) for downsampling
(e.g. <code>np.mean</code>, <code>np.max</code>, <code>np.sum</code>)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self.img and self.mask are downsampled accordingly in place</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def downsample(self, fact, func=np.mean):
    &#34;&#34;&#34;
    Downsamples image by applying `func` to `fact` pixels in both directions from
    each pixel

    Parameters
    ----------
    fact : int
        Number of pixels in each direction (x &amp; y) to downsample with
    func : function
        Numpy function to apply to squares of size (fact, fact, :) for downsampling
        (e.g. `np.mean`, `np.max`, `np.sum`)

    Returns
    -------
    self.img and self.mask are downsampled accordingly in place
    &#34;&#34;&#34;
    # downsample mask if mask available
    if self.mask is not None:
        self.mask = block_reduce(
            self.mask, block_size=(fact, fact), func=func, cval=0
        )
    # downsample image
    self.img = block_reduce(self.img, block_size=(fact, fact, 1), func=func, cval=0)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.equalize_hist"><code class="name flex">
<span>def <span class="ident">equalize_hist</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Contrast Limited Adaptive Histogram Equalization (CLAHE)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword args to pass to <code><a title="MILWRM.MxIF.CLAHE" href="#MILWRM.MxIF.CLAHE">CLAHE()</a></code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>self.img</code> is updated with exposure-adjusted values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def equalize_hist(self, **kwargs):
    &#34;&#34;&#34;
    Contrast Limited Adaptive Histogram Equalization (CLAHE)

    Parameters
    ----------
    **kwargs
        Keyword args to pass to `CLAHE()` function

    Returns
    -------
    `self.img` is updated with exposure-adjusted values
    &#34;&#34;&#34;
    self.img = CLAHE(self.img, **kwargs)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.log_normalize"><code class="name flex">
<span>def <span class="ident">log_normalize</span></span>(<span>self, pseudoval=1, mean=None, mask=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Log-normalizes values for each marker with <code>log10(arr/arr.mean() + pseudoval)</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pseudoval</code></strong> :&ensp;<code>float</code></dt>
<dd>Value to add to image values prior to log-transforming to avoid issues
with zeros</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>bool</code>, optional <code>(default=True)</code></dt>
<dd>Use tissue mask to determine marker mean factor for normalization. Default
<code>True</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Log-normalizes values in each channel of <code>self.img</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_normalize(self, pseudoval=1, mean=None, mask=True):
    &#34;&#34;&#34;
    Log-normalizes values for each marker with `log10(arr/arr.mean() + pseudoval)`

    Parameters
    ----------
    pseudoval : float
        Value to add to image values prior to log-transforming to avoid issues
        with zeros
    mask : bool, optional (default=True)
        Use tissue mask to determine marker mean factor for normalization. Default
        `True`.

    Returns
    -------
    Log-normalizes values in each channel of `self.img`
    &#34;&#34;&#34;
    if mean is not None:
        if mask:
            assert self.mask is not None, &#34;No tissue mask available&#34;
            for i in range(self.img.shape[2]):
                fact = mean[i]
                self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
        else:
            print(&#34;WARNING: Performing normalization without a tissue mask.&#34;)
            for i in range(self.img.shape[2]):
                fact = mean[i]
                self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
    else:
        print(&#34;mean calculated to perform log normalization&#34;)
        if mask:
            assert self.mask is not None, &#34;No tissue mask available&#34;
            for i in range(self.img.shape[2]):
                fact = self.img[:, :, i].mean()
                self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)
        else:
            print(&#34;WARNING: Performing normalization without a tissue mask.&#34;)
            for i in range(self.img.shape[2]):
                fact = self.img[:, :, i].mean()
                self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.plot_image_histogram"><code class="name flex">
<span>def <span class="ident">plot_image_histogram</span></span>(<span>self, channels=None, ncols=4, save_to=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot image histogram</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of channels by index or name to show</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code></dt>
<dd>Number sof columns for gridspec if plotting individual channels.</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. If <code>None</code>, show figure.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code>plt.imshow()</code> function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Gridspec object (for multiple features). Saves plot to file if <code>save_to</code> is
not <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_image_histogram(self, channels=None, ncols=4, save_to=None, **kwargs):

    &#34;&#34;&#34;
    Plot image histogram

    Parameters
    ----------
    channels : tuple of int or None, optional (default=`None`)
        List of channels by index or name to show
    ncols : int
        Number sof columns for gridspec if plotting individual channels.
    save_to : str or None
        Path to image file to save results. If `None`, show figure.
    **kwargs
        Arguments to pass to `plt.imshow()` function.

    Returns
    -------
    Gridspec object (for multiple features). Saves plot to file if `save_to` is
    not `None`.
    &#34;&#34;&#34;
    # calculate gridspec dimensions
    if len(channels) &lt;= ncols:
        n_rows, n_cols = 1, len(channels)
    else:
        n_rows, n_cols = ceil(len(channels) / ncols), ncols
    fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
    # arrange axes as subplots
    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
    # add plots to axes
    i = 0
    for channel in channels:
        ax = plt.subplot(gs[i])
        data = self[channel].copy()
        ax.hist(data.ravel(), bins=100, **kwargs)
        ax.set_title(channel, fontweight=&#34;bold&#34;, fontsize=16)
        i = i + 1
    fig.tight_layout()
    plt.show()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return gs</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Scales intensities to [0.0, 1.0]</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword args to pass to <code><a title="MILWRM.MxIF.scale_rgb" href="#MILWRM.MxIF.scale_rgb">scale_rgb()</a></code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Scales intensities of <code>self.img</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, **kwargs):
    &#34;&#34;&#34;
    Scales intensities to [0.0, 1.0]

    Parameters
    ----------
    **kwargs
        Keyword args to pass to `scale_rgb()` function

    Returns
    -------
    Scales intensities of `self.img`
    &#34;&#34;&#34;
    self.img = scale_rgb(self.img, **kwargs)</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self, channels=None, RGB=False, cbar=False, mask_out=True, ncols=4, figsize=(7, 7), save_to=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot image</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of channels by index or name to show</dd>
<dt><strong><code>RGB</code></strong> :&ensp;<code>bool</code></dt>
<dd>Treat 3- or 4-dimensional array as RGB image. If <code>False</code>, plot channels
individually.</dd>
<dt><strong><code>cbar</code></strong> :&ensp;<code>bool</code></dt>
<dd>Show colorbar for scale of image intensities if plotting individual
channels.</dd>
<dt><strong><code>mask_out</code></strong> :&ensp;<code>bool</code>, optional <code>(default=</code>True<code>)</code></dt>
<dd>Mask out non-tissue pixels prior to showing</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of columns for gridspec if plotting individual channels.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code></dt>
<dd>Size in inches of output figure.</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. If <code>None</code>, show figure.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code>plt.imshow()</code> function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object (if plotting one feature</code> or <code>RGB)</code> or <code>gridspec object (for</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>multiple features). Saves plot to file if <code>save_to</code> is not <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show(
    self,
    channels=None,
    RGB=False,
    cbar=False,
    mask_out=True,
    ncols=4,
    figsize=(7, 7),
    save_to=None,
    **kwargs,
):
    &#34;&#34;&#34;
    Plot image

    Parameters
    ----------
    channels : tuple of int or None, optional (default=`None`)
        List of channels by index or name to show
    RGB : bool
        Treat 3- or 4-dimensional array as RGB image. If `False`, plot channels
        individually.
    cbar : bool
        Show colorbar for scale of image intensities if plotting individual
        channels.
    mask_out : bool, optional (default=`True`)
        Mask out non-tissue pixels prior to showing
    ncols : int
        Number of columns for gridspec if plotting individual channels.
    figsize : tuple of float
        Size in inches of output figure.
    save_to : str or None
        Path to image file to save results. If `None`, show figure.
    **kwargs
        Arguments to pass to `plt.imshow()` function.

    Returns
    -------
    Matplotlib object (if plotting one feature or RGB) or gridspec object (for
    multiple features). Saves plot to file if `save_to` is not `None`.
    &#34;&#34;&#34;
    # if only one feature (2D), plot it quickly
    if self.img.ndim == 2:
        fig = plt.figure(figsize=figsize)
        if self.mask is not None and mask_out:
            im_tmp = self.img.copy()  # make copy for masking
            im_tmp[:, :][self.mask == 0] = np.nan  # area outside mask to NaN
            plt.imshow(im_tmp, **kwargs)
        else:
            plt.imshow(self.img, **kwargs)
        plt.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        if cbar:
            plt.colorbar(shrink=0.8)
        plt.tight_layout()
        if save_to:
            plt.savefig(
                fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
            )
        return fig
    # if image has multiple channels, plot them in gridspec
    if isinstance(channels, int):  # force channels into list if single integer
        channels = [channels]
    if isinstance(channels, str):  # force channels into int if single string
        channels = [self.ch.index(channels)]
    if checktype(channels):  # force channels into list of int if list of strings
        channels = [self.ch.index(x) for x in channels]
    if channels is None:  # if no channels are given, use all of them
        channels = [x for x in range(self.n_ch)]
    assert (
        len(channels) &lt;= self.n_ch
    ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
        self.n_ch, len(channels)
    )
    if RGB:
        # if third dim has 3 or 4 features, treat as RGB and plot it quickly
        assert (self.img.ndim == 3) &amp; (
            len(channels) == 3
        ), &#34;Need 3 dimensions and 3 given channels for an RGB image; shape = {}; channels given = {}&#34;.format(
            self.img.shape, len(channels)
        )
        fig = plt.figure(figsize=figsize)
        # rearrange channels to specified order
        im_tmp = np.dstack(
            [
                self.img[:, :, channels[0]],
                self.img[:, :, channels[1]],
                self.img[:, :, channels[2]],
            ]
        )
        if self.mask is not None and mask_out:
            for i in [0, 1, 2]:  # for 3-channel image
                im_tmp[:, :, i][self.mask == 0] = np.nan  # area outside mask NaN
        plt.imshow(im_tmp, **kwargs)
        # add legend for channel IDs
        custom_lines = [
            Line2D([0], [0], color=(1, 0, 0), lw=5),
            Line2D([0], [0], color=(0, 1, 0), lw=5),
            Line2D([0], [0], color=(0, 0, 1), lw=5),
        ]
        plt.legend(custom_lines, [self.ch[x] for x in channels], fontsize=&#34;medium&#34;)
        plt.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        plt.tight_layout()
        if save_to:
            plt.savefig(
                fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300
            )
        return fig
    # calculate gridspec dimensions
    if len(channels) &lt;= ncols:
        n_rows, n_cols = 1, len(channels)
    else:
        n_rows, n_cols = ceil(len(channels) / ncols), ncols
    fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
    # arrange axes as subplots
    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
    # add plots to axes
    i = 0
    for channel in channels:
        ax = plt.subplot(gs[i])
        if self.mask is not None and mask_out:
            im_tmp = self.img[:, :, channel].copy()  # make copy for masking
            im_tmp[self.mask == 0] = np.nan  # area outside mask NaN
            im = ax.imshow(im_tmp, **kwargs)
        else:
            im = ax.imshow(self.img[:, :, channel], **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=self.ch[channel],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        if cbar:
            _ = plt.colorbar(im, shrink=0.8)
        i = i + 1
    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.subsample_pixels"><code class="name flex">
<span>def <span class="ident">subsample_pixels</span></span>(<span>self, features, fract=0.2, random_state=18)</span>
</code></dt>
<dd>
<div class="desc"><p>Sub-samples fraction of pixels from the image randomly for each channel</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>fract</code></strong> :&ensp;<code>float</code>, optional <code>(default=0.2)</code></dt>
<dd>Fraction of cluster data from each image to randomly select
for model building</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tmp</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Clustering data from <code>image</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subsample_pixels(self, features, fract=0.2, random_state=18):
    &#34;&#34;&#34;
    Sub-samples fraction of pixels from the image randomly for each channel

    Parameters
    ----------
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    fract : float, optional (default=0.2)
        Fraction of cluster data from each image to randomly select
        for model building

    Returns
    -------
    tmp : np.array
        Clustering data from `image`

    &#34;&#34;&#34;
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [self.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [self.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(self.n_ch)]
    # subsample data for given image
    np.random.seed(random_state)
    tmp = []
    for i in range(self.img.shape[2]):
        tmp.append(self.img[:, :, i][self.mask != 0])
    tmp = np.column_stack(tmp)
    # select cluster data
    i = np.random.choice(tmp.shape[0], int(tmp.shape[0] * fract))
    tmp = tmp[np.ix_(i, features)]
    return tmp</code></pre>
</details>
</dd>
<dt id="MILWRM.MxIF.img.to_npz"><code class="name flex">
<span>def <span class="ident">to_npz</span></span>(<span>self, file)</span>
</code></dt>
<dd>
<div class="desc"><p>Save img object to compressed <code>.npz</code> file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to <code>.npz</code> file in which to save img object and metadata</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Writes object to <code>file</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_npz(self, file):
    &#34;&#34;&#34;
    Save img object to compressed `.npz` file

    Parameters
    ----------
    file : str
        Path to `.npz` file in which to save img object and metadata

    Returns
    -------
    Writes object to `file`
    &#34;&#34;&#34;
    print(&#34;Saving img object to {}...&#34;.format(file))
    if self.mask is None:
        np.savez_compressed(file, img=self.img, ch=self.ch)
    else:
        np.savez_compressed(file, img=self.img, ch=self.ch, mask=self.mask)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="MILWRM" href="index.html">MILWRM</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="MILWRM.MxIF.CLAHE" href="#MILWRM.MxIF.CLAHE">CLAHE</a></code></li>
<li><code><a title="MILWRM.MxIF.checktype" href="#MILWRM.MxIF.checktype">checktype</a></code></li>
<li><code><a title="MILWRM.MxIF.clip_values" href="#MILWRM.MxIF.clip_values">clip_values</a></code></li>
<li><code><a title="MILWRM.MxIF.scale_rgb" href="#MILWRM.MxIF.scale_rgb">scale_rgb</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="MILWRM.MxIF.img" href="#MILWRM.MxIF.img">img</a></code></h4>
<ul class="">
<li><code><a title="MILWRM.MxIF.img.blurring" href="#MILWRM.MxIF.img.blurring">blurring</a></code></li>
<li><code><a title="MILWRM.MxIF.img.calculate_non_zero_mean" href="#MILWRM.MxIF.img.calculate_non_zero_mean">calculate_non_zero_mean</a></code></li>
<li><code><a title="MILWRM.MxIF.img.clip" href="#MILWRM.MxIF.img.clip">clip</a></code></li>
<li><code><a title="MILWRM.MxIF.img.copy" href="#MILWRM.MxIF.img.copy">copy</a></code></li>
<li><code><a title="MILWRM.MxIF.img.create_tissue_mask" href="#MILWRM.MxIF.img.create_tissue_mask">create_tissue_mask</a></code></li>
<li><code><a title="MILWRM.MxIF.img.downsample" href="#MILWRM.MxIF.img.downsample">downsample</a></code></li>
<li><code><a title="MILWRM.MxIF.img.equalize_hist" href="#MILWRM.MxIF.img.equalize_hist">equalize_hist</a></code></li>
<li><code><a title="MILWRM.MxIF.img.from_npz" href="#MILWRM.MxIF.img.from_npz">from_npz</a></code></li>
<li><code><a title="MILWRM.MxIF.img.from_tiffs" href="#MILWRM.MxIF.img.from_tiffs">from_tiffs</a></code></li>
<li><code><a title="MILWRM.MxIF.img.log_normalize" href="#MILWRM.MxIF.img.log_normalize">log_normalize</a></code></li>
<li><code><a title="MILWRM.MxIF.img.plot_image_histogram" href="#MILWRM.MxIF.img.plot_image_histogram">plot_image_histogram</a></code></li>
<li><code><a title="MILWRM.MxIF.img.scale" href="#MILWRM.MxIF.img.scale">scale</a></code></li>
<li><code><a title="MILWRM.MxIF.img.show" href="#MILWRM.MxIF.img.show">show</a></code></li>
<li><code><a title="MILWRM.MxIF.img.subsample_pixels" href="#MILWRM.MxIF.img.subsample_pixels">subsample_pixels</a></code></li>
<li><code><a title="MILWRM.MxIF.img.to_npz" href="#MILWRM.MxIF.img.to_npz">to_npz</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>